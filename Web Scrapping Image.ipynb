{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44a6c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import datetime\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "240e178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\prave\\Downloads\\Compressed\\chromedriver.exe\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb02b3af",
   "metadata": {},
   "source": [
    "## Saree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4513bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Url_Saree='https://www.amazon.in/s?k=Sarees+%28women%29&ref=nb_sb_noss_2'\n",
    "driver.get(Url_Saree)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efbc2b04",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n",
      "Downloading 20 of 100 images\n",
      "Downloading 21 of 100 images\n",
      "Downloading 22 of 100 images\n",
      "Downloading 23 of 100 images\n",
      "Downloading 24 of 100 images\n",
      "Downloading 25 of 100 images\n",
      "Downloading 26 of 100 images\n",
      "Downloading 27 of 100 images\n",
      "Downloading 28 of 100 images\n",
      "Downloading 29 of 100 images\n",
      "Downloading 30 of 100 images\n",
      "Downloading 31 of 100 images\n",
      "Downloading 32 of 100 images\n",
      "Downloading 33 of 100 images\n",
      "Downloading 34 of 100 images\n",
      "Downloading 35 of 100 images\n",
      "Downloading 36 of 100 images\n",
      "Downloading 37 of 100 images\n",
      "Downloading 38 of 100 images\n",
      "Downloading 39 of 100 images\n",
      "Downloading 40 of 100 images\n",
      "Downloading 41 of 100 images\n",
      "Downloading 42 of 100 images\n",
      "Downloading 43 of 100 images\n",
      "Downloading 44 of 100 images\n",
      "Downloading 45 of 100 images\n",
      "Downloading 46 of 100 images\n",
      "Downloading 47 of 100 images\n",
      "Downloading 48 of 100 images\n",
      "Downloading 49 of 100 images\n",
      "Downloading 50 of 100 images\n",
      "Downloading 51 of 100 images\n",
      "Downloading 52 of 100 images\n",
      "Downloading 53 of 100 images\n",
      "Downloading 54 of 100 images\n",
      "Downloading 55 of 100 images\n",
      "Downloading 56 of 100 images\n",
      "Downloading 57 of 100 images\n",
      "Downloading 58 of 100 images\n",
      "Downloading 59 of 100 images\n",
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n",
      "Downloading 20 of 100 images\n",
      "Downloading 21 of 100 images\n",
      "Downloading 22 of 100 images\n",
      "Downloading 23 of 100 images\n",
      "Downloading 24 of 100 images\n",
      "Downloading 25 of 100 images\n",
      "Downloading 26 of 100 images\n",
      "Downloading 27 of 100 images\n",
      "Downloading 28 of 100 images\n",
      "Downloading 29 of 100 images\n",
      "Downloading 30 of 100 images\n",
      "Downloading 31 of 100 images\n",
      "Downloading 32 of 100 images\n",
      "Downloading 33 of 100 images\n",
      "Downloading 34 of 100 images\n",
      "Downloading 35 of 100 images\n",
      "Downloading 36 of 100 images\n",
      "Downloading 37 of 100 images\n",
      "Downloading 38 of 100 images\n",
      "Downloading 39 of 100 images\n",
      "Downloading 40 of 100 images\n",
      "Downloading 41 of 100 images\n",
      "Downloading 42 of 100 images\n",
      "Downloading 43 of 100 images\n",
      "Downloading 44 of 100 images\n",
      "Downloading 45 of 100 images\n",
      "Downloading 46 of 100 images\n",
      "Downloading 47 of 100 images\n",
      "Downloading 48 of 100 images\n",
      "Downloading 49 of 100 images\n",
      "Downloading 50 of 100 images\n",
      "Downloading 51 of 100 images\n",
      "Downloading 52 of 100 images\n",
      "Downloading 53 of 100 images\n",
      "Downloading 54 of 100 images\n",
      "Downloading 55 of 100 images\n",
      "Downloading 56 of 100 images\n",
      "Downloading 57 of 100 images\n",
      "Downloading 58 of 100 images\n",
      "Downloading 59 of 100 images\n",
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n",
      "Downloading 20 of 100 images\n",
      "Downloading 21 of 100 images\n",
      "Downloading 22 of 100 images\n",
      "Downloading 23 of 100 images\n",
      "Downloading 24 of 100 images\n",
      "Downloading 25 of 100 images\n",
      "Downloading 26 of 100 images\n",
      "Downloading 27 of 100 images\n",
      "Downloading 28 of 100 images\n",
      "Downloading 29 of 100 images\n",
      "Downloading 30 of 100 images\n",
      "Downloading 31 of 100 images\n",
      "Downloading 32 of 100 images\n",
      "Downloading 33 of 100 images\n",
      "Downloading 34 of 100 images\n",
      "Downloading 35 of 100 images\n",
      "Downloading 36 of 100 images\n",
      "Downloading 37 of 100 images\n",
      "Downloading 38 of 100 images\n",
      "Downloading 39 of 100 images\n",
      "Downloading 40 of 100 images\n",
      "Downloading 41 of 100 images\n",
      "Downloading 42 of 100 images\n",
      "Downloading 43 of 100 images\n",
      "Downloading 44 of 100 images\n",
      "Downloading 45 of 100 images\n",
      "Downloading 46 of 100 images\n",
      "Downloading 47 of 100 images\n",
      "Downloading 48 of 100 images\n",
      "Downloading 49 of 100 images\n",
      "Downloading 50 of 100 images\n",
      "Downloading 51 of 100 images\n",
      "Downloading 52 of 100 images\n",
      "Downloading 53 of 100 images\n",
      "Downloading 54 of 100 images\n",
      "Downloading 55 of 100 images\n",
      "Downloading 56 of 100 images\n",
      "Downloading 57 of 100 images\n",
      "Downloading 58 of 100 images\n",
      "Downloading 59 of 100 images\n"
     ]
    }
   ],
   "source": [
    "a=0\n",
    "\n",
    "for i in range(0,6): \n",
    "            images = driver.find_elements(By.XPATH,'//img[@class=\"s-image\"]')\n",
    "\n",
    "            img_urls = []\n",
    "            img_data = []\n",
    "            for image in images:\n",
    "                source= image.get_attribute('src')\n",
    "                if source is not None:\n",
    "                    if(source[0:4] == 'http'):\n",
    "                        img_urls.append(source)\n",
    "                        \n",
    "                        \n",
    "            b=len(img_urls)\n",
    "            for i in range(b):\n",
    "                if i >= 1000:\n",
    "                    break\n",
    "                print(\"Downloading {0} of {1} images\" .format(i, 100))\n",
    "                response= requests.get(img_urls[i])\n",
    "                file = open(r\"C:\\Users\\prave\\Jupyter\\image\\Train\\Saree\"+str(a)+str(i)+\".jpg\", \"wb\")\n",
    "                file.write(response.content) \n",
    "                time.sleep(2)\n",
    "                \n",
    "            try:\n",
    "                button=driver.find_element(By.XPATH,\"//*[contains(text(), 'Next')]\")\n",
    "                driver.execute_script(\"arguments[0].click();\", button)\n",
    "                a+=1\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "                time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdabdeda",
   "metadata": {},
   "source": [
    "## Trousers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f57dd8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Url_Trousers='https://www.amazon.in/s?k=trousers&ref=nb_sb_noss_2'\n",
    "driver.get(Url_Trousers)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ace30b3d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n",
      "Downloading 20 of 100 images\n",
      "Downloading 21 of 100 images\n",
      "Downloading 22 of 100 images\n",
      "Downloading 23 of 100 images\n",
      "Downloading 24 of 100 images\n",
      "Downloading 25 of 100 images\n",
      "Downloading 26 of 100 images\n",
      "Downloading 27 of 100 images\n",
      "Downloading 28 of 100 images\n",
      "Downloading 29 of 100 images\n",
      "Downloading 30 of 100 images\n",
      "Downloading 31 of 100 images\n",
      "Downloading 32 of 100 images\n",
      "Downloading 33 of 100 images\n",
      "Downloading 34 of 100 images\n",
      "Downloading 35 of 100 images\n",
      "Downloading 36 of 100 images\n",
      "Downloading 37 of 100 images\n",
      "Downloading 38 of 100 images\n",
      "Downloading 39 of 100 images\n",
      "Downloading 40 of 100 images\n",
      "Downloading 41 of 100 images\n",
      "Downloading 42 of 100 images\n",
      "Downloading 43 of 100 images\n",
      "Downloading 44 of 100 images\n",
      "Downloading 45 of 100 images\n",
      "Downloading 46 of 100 images\n",
      "Downloading 47 of 100 images\n",
      "Downloading 48 of 100 images\n",
      "Downloading 49 of 100 images\n",
      "Downloading 50 of 100 images\n",
      "Downloading 51 of 100 images\n",
      "Downloading 52 of 100 images\n",
      "Downloading 53 of 100 images\n",
      "Downloading 54 of 100 images\n",
      "Downloading 55 of 100 images\n",
      "Downloading 56 of 100 images\n",
      "Downloading 57 of 100 images\n",
      "Downloading 58 of 100 images\n",
      "Downloading 59 of 100 images\n",
      "Downloading 60 of 100 images\n",
      "Downloading 61 of 100 images\n",
      "Downloading 62 of 100 images\n",
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n",
      "Downloading 20 of 100 images\n",
      "Downloading 21 of 100 images\n",
      "Downloading 22 of 100 images\n",
      "Downloading 23 of 100 images\n",
      "Downloading 24 of 100 images\n",
      "Downloading 25 of 100 images\n",
      "Downloading 26 of 100 images\n",
      "Downloading 27 of 100 images\n",
      "Downloading 28 of 100 images\n",
      "Downloading 29 of 100 images\n",
      "Downloading 30 of 100 images\n",
      "Downloading 31 of 100 images\n",
      "Downloading 32 of 100 images\n",
      "Downloading 33 of 100 images\n",
      "Downloading 34 of 100 images\n",
      "Downloading 35 of 100 images\n",
      "Downloading 36 of 100 images\n",
      "Downloading 37 of 100 images\n",
      "Downloading 38 of 100 images\n",
      "Downloading 39 of 100 images\n",
      "Downloading 40 of 100 images\n",
      "Downloading 41 of 100 images\n",
      "Downloading 42 of 100 images\n",
      "Downloading 43 of 100 images\n",
      "Downloading 44 of 100 images\n",
      "Downloading 45 of 100 images\n",
      "Downloading 46 of 100 images\n",
      "Downloading 47 of 100 images\n",
      "Downloading 48 of 100 images\n",
      "Downloading 49 of 100 images\n",
      "Downloading 50 of 100 images\n",
      "Downloading 51 of 100 images\n",
      "Downloading 52 of 100 images\n",
      "Downloading 53 of 100 images\n",
      "Downloading 54 of 100 images\n",
      "Downloading 55 of 100 images\n",
      "Downloading 56 of 100 images\n",
      "Downloading 57 of 100 images\n",
      "Downloading 58 of 100 images\n",
      "Downloading 59 of 100 images\n",
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n",
      "Downloading 20 of 100 images\n",
      "Downloading 21 of 100 images\n",
      "Downloading 22 of 100 images\n",
      "Downloading 23 of 100 images\n",
      "Downloading 24 of 100 images\n",
      "Downloading 25 of 100 images\n",
      "Downloading 26 of 100 images\n",
      "Downloading 27 of 100 images\n",
      "Downloading 28 of 100 images\n",
      "Downloading 29 of 100 images\n",
      "Downloading 30 of 100 images\n",
      "Downloading 31 of 100 images\n",
      "Downloading 32 of 100 images\n",
      "Downloading 33 of 100 images\n",
      "Downloading 34 of 100 images\n",
      "Downloading 35 of 100 images\n",
      "Downloading 36 of 100 images\n",
      "Downloading 37 of 100 images\n",
      "Downloading 38 of 100 images\n",
      "Downloading 39 of 100 images\n",
      "Downloading 40 of 100 images\n",
      "Downloading 41 of 100 images\n",
      "Downloading 42 of 100 images\n",
      "Downloading 43 of 100 images\n",
      "Downloading 44 of 100 images\n",
      "Downloading 45 of 100 images\n",
      "Downloading 46 of 100 images\n",
      "Downloading 47 of 100 images\n",
      "Downloading 48 of 100 images\n",
      "Downloading 49 of 100 images\n",
      "Downloading 50 of 100 images\n",
      "Downloading 51 of 100 images\n",
      "Downloading 52 of 100 images\n",
      "Downloading 53 of 100 images\n",
      "Downloading 54 of 100 images\n",
      "Downloading 55 of 100 images\n",
      "Downloading 56 of 100 images\n",
      "Downloading 57 of 100 images\n",
      "Downloading 58 of 100 images\n",
      "Downloading 59 of 100 images\n"
     ]
    }
   ],
   "source": [
    "a=0\n",
    "\n",
    "for i in range(0,6): \n",
    "            images = driver.find_elements(By.XPATH,'//img[@class=\"s-image\"]')\n",
    "\n",
    "            img_urls = []\n",
    "            img_data = []\n",
    "            for image in images:\n",
    "                source= image.get_attribute('src')\n",
    "                if source is not None:\n",
    "                    if(source[0:4] == 'http'):\n",
    "                        img_urls.append(source)\n",
    "                        \n",
    "                        \n",
    "            b=len(img_urls)\n",
    "            for i in range(b):\n",
    "                if i >= 1000:\n",
    "                    break\n",
    "                print(\"Downloading {0} of {1} images\" .format(i, 100))\n",
    "                response= requests.get(img_urls[i])\n",
    "                file = open(r\"C:\\Users\\prave\\Jupyter\\image\\Train\\Trousers\\Trouser\"+str(a)+str(i)+\".jpg\", \"wb\")\n",
    "                file.write(response.content) \n",
    "                time.sleep(2)\n",
    "                \n",
    "            try:\n",
    "                button=driver.find_element(By.XPATH,\"//*[contains(text(), 'Next')]\")\n",
    "                driver.execute_script(\"arguments[0].click();\", button)\n",
    "                a+=1\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "                time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ec8656",
   "metadata": {},
   "source": [
    "## Jeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "418d28ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Url_Jeans='https://www.amazon.in/s?k=Jeans&ref=nb_sb_noss_2'\n",
    "driver.get(Url_Jeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4adf918d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n",
      "Downloading 20 of 100 images\n",
      "Downloading 21 of 100 images\n",
      "Downloading 22 of 100 images\n",
      "Downloading 23 of 100 images\n",
      "Downloading 24 of 100 images\n",
      "Downloading 25 of 100 images\n",
      "Downloading 26 of 100 images\n",
      "Downloading 27 of 100 images\n",
      "Downloading 28 of 100 images\n",
      "Downloading 29 of 100 images\n",
      "Downloading 30 of 100 images\n",
      "Downloading 31 of 100 images\n",
      "Downloading 32 of 100 images\n",
      "Downloading 33 of 100 images\n",
      "Downloading 34 of 100 images\n",
      "Downloading 35 of 100 images\n",
      "Downloading 36 of 100 images\n",
      "Downloading 37 of 100 images\n",
      "Downloading 38 of 100 images\n",
      "Downloading 39 of 100 images\n",
      "Downloading 40 of 100 images\n",
      "Downloading 41 of 100 images\n",
      "Downloading 42 of 100 images\n",
      "Downloading 43 of 100 images\n",
      "Downloading 44 of 100 images\n",
      "Downloading 45 of 100 images\n",
      "Downloading 46 of 100 images\n",
      "Downloading 47 of 100 images\n",
      "Downloading 48 of 100 images\n",
      "Downloading 49 of 100 images\n",
      "Downloading 50 of 100 images\n",
      "Downloading 51 of 100 images\n",
      "Downloading 52 of 100 images\n",
      "Downloading 53 of 100 images\n",
      "Downloading 54 of 100 images\n",
      "Downloading 55 of 100 images\n",
      "Downloading 56 of 100 images\n",
      "Downloading 57 of 100 images\n",
      "Downloading 58 of 100 images\n",
      "Downloading 59 of 100 images\n",
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n",
      "Downloading 20 of 100 images\n",
      "Downloading 21 of 100 images\n",
      "Downloading 22 of 100 images\n",
      "Downloading 23 of 100 images\n",
      "Downloading 24 of 100 images\n",
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n",
      "Downloading 20 of 100 images\n",
      "Downloading 21 of 100 images\n",
      "Downloading 22 of 100 images\n",
      "Downloading 23 of 100 images\n",
      "Downloading 24 of 100 images\n",
      "Downloading 25 of 100 images\n",
      "Downloading 26 of 100 images\n",
      "Downloading 27 of 100 images\n",
      "Downloading 28 of 100 images\n",
      "Downloading 29 of 100 images\n",
      "Downloading 30 of 100 images\n",
      "Downloading 31 of 100 images\n",
      "Downloading 32 of 100 images\n",
      "Downloading 33 of 100 images\n",
      "Downloading 34 of 100 images\n",
      "Downloading 35 of 100 images\n",
      "Downloading 36 of 100 images\n",
      "Downloading 37 of 100 images\n",
      "Downloading 38 of 100 images\n",
      "Downloading 39 of 100 images\n",
      "Downloading 40 of 100 images\n",
      "Downloading 41 of 100 images\n",
      "Downloading 42 of 100 images\n",
      "Downloading 43 of 100 images\n",
      "Downloading 44 of 100 images\n",
      "Downloading 45 of 100 images\n",
      "Downloading 46 of 100 images\n",
      "Downloading 47 of 100 images\n",
      "Downloading 48 of 100 images\n",
      "Downloading 49 of 100 images\n",
      "Downloading 50 of 100 images\n",
      "Downloading 51 of 100 images\n",
      "Downloading 52 of 100 images\n",
      "Downloading 53 of 100 images\n",
      "Downloading 54 of 100 images\n",
      "Downloading 55 of 100 images\n",
      "Downloading 56 of 100 images\n",
      "Downloading 57 of 100 images\n",
      "Downloading 58 of 100 images\n",
      "Downloading 59 of 100 images\n"
     ]
    }
   ],
   "source": [
    "a=0\n",
    "\n",
    "for i in range(0,6): \n",
    "            images = driver.find_elements(By.XPATH,'//img[@class=\"s-image\"]')\n",
    "\n",
    "            img_urls = []\n",
    "            img_data = []\n",
    "            for image in images:\n",
    "                source= image.get_attribute('src')\n",
    "                if source is not None:\n",
    "                    if(source[0:4] == 'http'):\n",
    "                        img_urls.append(source)\n",
    "                        \n",
    "                        \n",
    "            b=len(img_urls)\n",
    "            for i in range(b):\n",
    "                if i >= 1000:\n",
    "                    break\n",
    "                print(\"Downloading {0} of {1} images\" .format(i, 100))\n",
    "                response= requests.get(img_urls[i])\n",
    "                file = open(r\"C:\\Users\\prave\\Jupyter\\image\\Train\\Jeans\\Jean\"+str(a)+str(i)+\".jpg\", \"wb\")\n",
    "                file.write(response.content) \n",
    "                time.sleep(2)\n",
    "                \n",
    "            try:\n",
    "                button=driver.find_element(By.XPATH,\"//*[contains(text(), 'Next')]\")\n",
    "                driver.execute_script(\"arguments[0].click();\", button)\n",
    "                a+=1\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "                time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae83e725",
   "metadata": {},
   "source": [
    "## Test\n",
    "### Sarees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b7a7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Url_Sarees='https://www.flipkart.com/womens-sarees/pr?sid=clo%2C8on%2Czpd%2C9og&otracker[]=categorytree&otracker[]=nmenu_sub_Women_0_Sarees'\n",
    "driver.get(Url_Sarees)\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1e195bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n",
      "Downloading 20 of 100 images\n",
      "Downloading 21 of 100 images\n",
      "Downloading 22 of 100 images\n",
      "Downloading 23 of 100 images\n",
      "Downloading 24 of 100 images\n",
      "Downloading 25 of 100 images\n",
      "Downloading 26 of 100 images\n",
      "Downloading 27 of 100 images\n",
      "Downloading 28 of 100 images\n",
      "Downloading 29 of 100 images\n",
      "Downloading 30 of 100 images\n",
      "Downloading 31 of 100 images\n",
      "Downloading 32 of 100 images\n",
      "Downloading 33 of 100 images\n",
      "Downloading 34 of 100 images\n",
      "Downloading 35 of 100 images\n",
      "Downloading 36 of 100 images\n",
      "Downloading 37 of 100 images\n",
      "Downloading 38 of 100 images\n",
      "Downloading 39 of 100 images\n"
     ]
    }
   ],
   "source": [
    "#scrapping images\n",
    "a=0\n",
    "images = driver.find_elements(By.XPATH,'//img[@class=\"_2r_T1I\"]')\n",
    "\n",
    "img_urls = []\n",
    "img_data = []\n",
    "for image in images:\n",
    "    source= image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] == 'http'):\n",
    "            img_urls.append(source)\n",
    "\n",
    "\n",
    "b=len(img_urls)\n",
    "for i in range(b):\n",
    "    if i >= 1000:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 100))\n",
    "    response= requests.get(img_urls[i])\n",
    "    file = open(r\"C:\\Users\\prave\\Jupyter\\image\\Test\\sarees\\saree\"+str(a)+str(i)+\".jpg\", \"wb\")\n",
    "    file.write(response.content) \n",
    "    time.sleep(2)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd13e0e0",
   "metadata": {},
   "source": [
    "### Trousers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6c4ccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Url_Trousers='https://www.flipkart.com/clothing-and-accessories/bottomwear/trouser/men-trouser/pr?sid=clo%2Cvua%2Cmle%2Clhk&otracker=categorytree&p%5B%5D=facets.occasion%255B%255D%3DFormal&otracker=nmenu_sub_Men_0_Formal%20Trousers'\n",
    "driver.get(Url_Trousers)\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "661834dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n",
      "Downloading 20 of 100 images\n",
      "Downloading 21 of 100 images\n",
      "Downloading 22 of 100 images\n",
      "Downloading 23 of 100 images\n",
      "Downloading 24 of 100 images\n",
      "Downloading 25 of 100 images\n",
      "Downloading 26 of 100 images\n",
      "Downloading 27 of 100 images\n",
      "Downloading 28 of 100 images\n",
      "Downloading 29 of 100 images\n",
      "Downloading 30 of 100 images\n",
      "Downloading 31 of 100 images\n",
      "Downloading 32 of 100 images\n",
      "Downloading 33 of 100 images\n",
      "Downloading 34 of 100 images\n",
      "Downloading 35 of 100 images\n",
      "Downloading 36 of 100 images\n",
      "Downloading 37 of 100 images\n",
      "Downloading 38 of 100 images\n",
      "Downloading 39 of 100 images\n"
     ]
    }
   ],
   "source": [
    "#scrapping images\n",
    "a=0\n",
    "images = driver.find_elements(By.XPATH,'//img[@class=\"_2r_T1I\"]')\n",
    "\n",
    "img_urls = []\n",
    "img_data = []\n",
    "for image in images:\n",
    "    source= image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] == 'http'):\n",
    "            img_urls.append(source)\n",
    "\n",
    "\n",
    "b=len(img_urls)\n",
    "for i in range(b):\n",
    "    if i >= 1000:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 100))\n",
    "    response= requests.get(img_urls[i])\n",
    "    file = open(r\"C:\\Users\\prave\\Jupyter\\image\\Test\\Trousers\\Trouser\"+str(a)+str(i)+\".jpg\", \"wb\")\n",
    "    file.write(response.content) \n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31493321",
   "metadata": {},
   "source": [
    "### Jaens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cd63543",
   "metadata": {},
   "outputs": [],
   "source": [
    "Url_Jeans='https://www.flipkart.com/search?q=jeans&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off'\n",
    "driver.get(Url_Jeans)\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89727348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 100 images\n",
      "Downloading 1 of 100 images\n",
      "Downloading 2 of 100 images\n",
      "Downloading 3 of 100 images\n",
      "Downloading 4 of 100 images\n",
      "Downloading 5 of 100 images\n",
      "Downloading 6 of 100 images\n",
      "Downloading 7 of 100 images\n",
      "Downloading 8 of 100 images\n",
      "Downloading 9 of 100 images\n",
      "Downloading 10 of 100 images\n",
      "Downloading 11 of 100 images\n",
      "Downloading 12 of 100 images\n",
      "Downloading 13 of 100 images\n",
      "Downloading 14 of 100 images\n",
      "Downloading 15 of 100 images\n",
      "Downloading 16 of 100 images\n",
      "Downloading 17 of 100 images\n",
      "Downloading 18 of 100 images\n",
      "Downloading 19 of 100 images\n",
      "Downloading 20 of 100 images\n",
      "Downloading 21 of 100 images\n",
      "Downloading 22 of 100 images\n",
      "Downloading 23 of 100 images\n",
      "Downloading 24 of 100 images\n",
      "Downloading 25 of 100 images\n",
      "Downloading 26 of 100 images\n",
      "Downloading 27 of 100 images\n",
      "Downloading 28 of 100 images\n",
      "Downloading 29 of 100 images\n",
      "Downloading 30 of 100 images\n",
      "Downloading 31 of 100 images\n",
      "Downloading 32 of 100 images\n",
      "Downloading 33 of 100 images\n",
      "Downloading 34 of 100 images\n",
      "Downloading 35 of 100 images\n",
      "Downloading 36 of 100 images\n",
      "Downloading 37 of 100 images\n",
      "Downloading 38 of 100 images\n",
      "Downloading 39 of 100 images\n"
     ]
    }
   ],
   "source": [
    "#scrapping images\n",
    "a=0\n",
    "images = driver.find_elements(By.XPATH,'//img[@class=\"_2r_T1I\"]')\n",
    "\n",
    "img_urls = []\n",
    "img_data = []\n",
    "for image in images:\n",
    "    source= image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] == 'http'):\n",
    "            img_urls.append(source)\n",
    "\n",
    "\n",
    "b=len(img_urls)\n",
    "for i in range(b):\n",
    "    if i >= 1000:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 100))\n",
    "    response= requests.get(img_urls[i])\n",
    "    file = open(r\"C:\\Users\\prave\\Jupyter\\image\\Test\\Jaens\\Jaen\"+str(a)+str(i)+\".jpg\", \"wb\")\n",
    "    file.write(response.content) \n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b6bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
